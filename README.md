# Machine-Learning-Fundamentals

## Project Overview
This repository contains implementations of various machine learning algorithms written from scratch in Python. It is designed to demonstrate the underlying mechanics of machine learning models and to serve as an educational tool for those interested in learning how these algorithms work internally.

## Implemented Algorithms
- **Naive Bayes:** A probabilistic classifier based on applying Bayes' theorem.
- **Decision Trees:** A model that uses a tree-like model for decisions. (Classifier and Regressor)
- **Mean Shift:** A hierarchical clustering algorithm that assigns data points to clusters iteratively.
- **AdaBoost:** An ensemble boosting classifier that works by weighting the observations.
- **Gaussian Mixture Model:** A probabilistic model for representing normally distributed subpopulations.
- **K-Means:** A clustering algorithm that partitions observations into k clusters.
- **K-Nearest Neighbors (KNN):** A non-parametric method used for classification and regression.
- **Linear Discriminant Analysis (LDA):** A classifier with a linear decision boundary.
- **Linear Regression:** A linear approach to modeling the relationship between a dependent variable and one or more independent variables.
- **Logistic Regression:** A regression analysis used to predict the outcome of a categorical dependent variable.
- **Perceptron:** A simple algorithm suitable for large scale learning.
- **Principal Component Analysis (PCA):** A technique used to emphasize variation and bring out strong patterns in a dataset.
- **Random Forests:** An ensemble learning method for classification, regression, and other tasks.(Classifier and Regressor)

